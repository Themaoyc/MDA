{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2f18355",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# set output path\n",
    "# os.chdir(\"\")\n",
    "import errno\n",
    "import time\n",
    "import hashlib\n",
    "from multiprocessing.pool import ThreadPool\n",
    "from typing import Callable\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edb8989e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Core:\n",
    "\n",
    "    \"\"\"\n",
    "    Base class that provides features which are used across the package\n",
    "    \"\"\"\n",
    "\n",
    "    # Base URL of the Meteostat bulk data interface\n",
    "    endpoint: str = 'https://bulk.meteostat.net/v2/'\n",
    "\n",
    "    # Location of the cache directory\n",
    "    cache_dir: str = os.path.expanduser(\n",
    "        '~') + os.sep + '.meteostat' + os.sep + 'cache'\n",
    "\n",
    "    # Maximum age of a cached file in seconds\n",
    "    max_age: int = 24 * 60 * 60\n",
    "\n",
    "    # Maximum number of threads used for downloading files\n",
    "    max_threads: int = 1\n",
    "\n",
    "    def _get_file_path(\n",
    "        self,\n",
    "        subdir: str,\n",
    "        path: str\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        Get the local file path\n",
    "        \"\"\"\n",
    "\n",
    "        # Get file ID\n",
    "        file = hashlib.md5(path.encode('utf-8')).hexdigest()\n",
    "\n",
    "        # Return path\n",
    "        return self.cache_dir + os.sep + subdir + os.sep + file\n",
    "\n",
    "    def _file_in_cache(\n",
    "        self,\n",
    "        path: str\n",
    "    ) -> bool:\n",
    "        \"\"\"\n",
    "        Check if a file exists in the local cache\n",
    "        \"\"\"\n",
    "\n",
    "        # Get directory\n",
    "        directory = os.path.dirname(path)\n",
    "\n",
    "        # Make sure the cache directory exists\n",
    "        if not os.path.exists(directory):\n",
    "            try:\n",
    "                os.makedirs(directory)\n",
    "            except OSError as creation_error:\n",
    "                if creation_error.errno == errno.EEXIST:\n",
    "                    pass\n",
    "                else:\n",
    "                    raise Exception(\n",
    "                        'Cannot create cache directory') from creation_error\n",
    "\n",
    "        # Return the file path if it exists\n",
    "        if os.path.isfile(path) and time.time() - \\\n",
    "                os.path.getmtime(path) <= self.max_age:\n",
    "            return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    @staticmethod\n",
    "    def _processing_handler(\n",
    "        datasets: list,\n",
    "        load: Callable[[dict], None],\n",
    "        max_threads: int\n",
    "    ) -> None:\n",
    "\n",
    "        # Single-thread processing\n",
    "        if max_threads < 2:\n",
    "\n",
    "            for dataset in datasets:\n",
    "                load(*dataset)\n",
    "\n",
    "        # Multi-thread processing\n",
    "        else:\n",
    "\n",
    "            pool = ThreadPool(max_threads)\n",
    "            pool.starmap(load, datasets)\n",
    "\n",
    "            # Wait for Pool to finish\n",
    "            pool.close()\n",
    "            pool.join()\n",
    "\n",
    "    def _load_handler(\n",
    "        self,\n",
    "        path: str,\n",
    "        columns: list,\n",
    "        types: dict,\n",
    "        parse_dates: list,\n",
    "        coerce_dates: bool = False\n",
    "    ) -> pd.DataFrame:\n",
    "\n",
    "        try:\n",
    "\n",
    "            # Read CSV file from Meteostat endpoint\n",
    "            df = pd.read_csv(\n",
    "                self.endpoint + path,\n",
    "                compression='gzip',\n",
    "                names=columns,\n",
    "                dtype=types,\n",
    "                parse_dates=parse_dates)\n",
    "\n",
    "            # Force datetime conversion\n",
    "            if coerce_dates:\n",
    "                df.iloc[:, parse_dates] = df.iloc[:, parse_dates].apply(\n",
    "                    pd.to_datetime, errors='coerce')\n",
    "\n",
    "        except BaseException:\n",
    "\n",
    "            # Create empty DataFrane\n",
    "            df = pd.DataFrame(columns=[*types])\n",
    "\n",
    "        # Return DataFrame\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def _validate_series(\n",
    "        df: pd.DataFrame,\n",
    "        station: str\n",
    "    ) -> pd.DataFrame:\n",
    "\n",
    "        # Add missing column(s)\n",
    "        if 'time' not in df.columns:\n",
    "            df['time'] = None\n",
    "\n",
    "        # Add weather station ID\n",
    "        df['station'] = station\n",
    "\n",
    "        # Set index\n",
    "        df = df.set_index(['station', 'time'])\n",
    "\n",
    "        # Return DataFrame\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def _weighted_average(step: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Calculate weighted average from grouped data\n",
    "        \"\"\"\n",
    "\n",
    "        data = np.ma.masked_array(step, np.isnan(step))\n",
    "        data = np.ma.average(data, axis=0, weights=data[:, -1])\n",
    "        data = data.filled(np.NaN)\n",
    "\n",
    "        return pd.DataFrame(data=[data], columns=step.columns)\n",
    "\n",
    "    @classmethod\n",
    "    def clear_cache(\n",
    "        cls,\n",
    "        max_age: int = None\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Clear the cache\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "\n",
    "            if os.path.exists(cls.cache_dir + os.sep + cls.cache_subdir):\n",
    "\n",
    "                # Set max_age\n",
    "                if max_age is None:\n",
    "                    max_age = cls.max_age\n",
    "\n",
    "                # Get current time\n",
    "                now = time.time()\n",
    "\n",
    "                # Go through all files\n",
    "                for file in os.listdir(\n",
    "                        cls.cache_dir + os.sep + cls.cache_subdir):\n",
    "\n",
    "                    # Get full path\n",
    "                    path = os.path.join(\n",
    "                        cls.cache_dir + os.sep + cls.cache_subdir, file)\n",
    "\n",
    "                    # Check if file is older than max_age\n",
    "                    if now - \\\n",
    "                            os.path.getmtime(path) > max_age and os.path.isfile(path):\n",
    "                        # Delete file\n",
    "                        os.remove(path)\n",
    "\n",
    "        except BaseException as clear_error:\n",
    "            raise Exception('Cannot clear cache') from clear_error\n",
    "\n",
    "    @staticmethod\n",
    "    def _degree_mean(data: pd.Series):\n",
    "        \"\"\"\n",
    "        Return the mean of a list of degrees\n",
    "        \"\"\"\n",
    "\n",
    "        rads = np.deg2rad(data)\n",
    "        sums = np.arctan2(np.sum(np.sin(rads)), np.sum(np.cos(rads)))\n",
    "        return (np.rad2deg(sums) + 360) % 360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d1695bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from math import cos, sqrt, radians\n",
    "from copy import copy\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Union\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class Stations(Core):\n",
    "\n",
    "    \"\"\"\n",
    "    Select weather stations from the full list of stations\n",
    "    \"\"\"\n",
    "\n",
    "    # The cache subdirectory\n",
    "    cache_subdir: str = 'stations'\n",
    "\n",
    "    # The list of selected weather Stations\n",
    "    stations = None\n",
    "\n",
    "    # Raw data columns\n",
    "    _columns: list = [\n",
    "        'id',\n",
    "        'name',\n",
    "        'country',\n",
    "        'region',\n",
    "        'wmo',\n",
    "        'icao',\n",
    "        'latitude',\n",
    "        'longitude',\n",
    "        'elevation',\n",
    "        'timezone',\n",
    "        'hourly_start',\n",
    "        'hourly_end',\n",
    "        'daily_start',\n",
    "        'daily_end'\n",
    "    ]\n",
    "\n",
    "    # Processed data columns with types\n",
    "    _types: dict = {\n",
    "        'id': 'string',\n",
    "        'name': 'object',\n",
    "        'country': 'string',\n",
    "        'region': 'string',\n",
    "        'wmo': 'string',\n",
    "        'icao': 'string',\n",
    "        'latitude': 'float64',\n",
    "        'longitude': 'float64',\n",
    "        'elevation': 'float64',\n",
    "        'timezone': 'string'\n",
    "    }\n",
    "\n",
    "    # Columns for date parsing\n",
    "    _parse_dates: list = [10, 11, 12, 13]\n",
    "\n",
    "    def _load(self) -> None:\n",
    "        \"\"\"\n",
    "        Load file from Meteostat\n",
    "        \"\"\"\n",
    "\n",
    "        # File name\n",
    "        file = 'stations/lib.csv.gz'\n",
    "\n",
    "        # Get local file path\n",
    "        path = self._get_file_path(self.cache_subdir, file)\n",
    "\n",
    "        # Check if file in cache\n",
    "        if self.max_age > 0 and self._file_in_cache(path):\n",
    "\n",
    "            # Read cached data\n",
    "            df = pd.read_pickle(path)\n",
    "\n",
    "        else:\n",
    "\n",
    "            # Get data from Meteostat\n",
    "            df = self._load_handler(\n",
    "                file,\n",
    "                self._columns,\n",
    "                self._types,\n",
    "                self._parse_dates,\n",
    "                True)\n",
    "\n",
    "            # Add index\n",
    "            df = df.set_index('id')\n",
    "\n",
    "            # Save as Pickle\n",
    "            if self.max_age > 0:\n",
    "                df.to_pickle(path)\n",
    "\n",
    "        # Set data\n",
    "        self.stations = df\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "\n",
    "        # Get all weather stations\n",
    "        self._load()\n",
    "\n",
    "        # Clear cache\n",
    "        if self.max_age > 0:\n",
    "            self.clear_cache()\n",
    "\n",
    "    def id(\n",
    "        self,\n",
    "        organization: str,\n",
    "        code: str\n",
    "    ) -> 'Stations':\n",
    "        \"\"\"\n",
    "        Get weather station by identifier\n",
    "        \"\"\"\n",
    "\n",
    "        # Create temporal instance\n",
    "        temp = copy(self)\n",
    "\n",
    "        if isinstance(code, str):\n",
    "            code = [code]\n",
    "\n",
    "        if organization == 'meteostat':\n",
    "            temp.stations = temp.stations[temp.stations.index.isin(code)]\n",
    "        else:\n",
    "            temp.stations = temp.stations[temp.stations[organization].isin(\n",
    "                code)]\n",
    "\n",
    "        # Return self\n",
    "        return temp\n",
    "\n",
    "    def nearby(\n",
    "        self,\n",
    "        lat: float,\n",
    "        lon: float,\n",
    "        radius: int = None\n",
    "    ) -> 'Stations':\n",
    "        \"\"\"\n",
    "        Sort/filter weather stations by physical distance\n",
    "        \"\"\"\n",
    "\n",
    "        # Create temporal instance\n",
    "        temp = copy(self)\n",
    "\n",
    "        # Calculate distance between weather station and geo point\n",
    "        def distance(station, point) -> float:\n",
    "            # Earth radius in m\n",
    "            radius = 6371000\n",
    "\n",
    "            x = (radians(point[1]) - radians(station['longitude'])) * \\\n",
    "                cos(0.5 * (radians(point[0]) + radians(station['latitude'])))\n",
    "            y = (radians(point[0]) - radians(station['latitude']))\n",
    "\n",
    "            return radius * sqrt(x * x + y * y)\n",
    "\n",
    "        # Get distance for each stationsd\n",
    "        temp.stations['distance'] = temp.stations.apply(\n",
    "            lambda station: distance(station, [lat, lon]), axis=1)\n",
    "\n",
    "        # Filter by radius\n",
    "        if radius is not None:\n",
    "            temp.stations = temp.stations[temp.stations['distance'] <= radius]\n",
    "\n",
    "        # Sort stations by distance\n",
    "        temp.stations.columns.str.strip()\n",
    "        temp.stations = temp.stations.sort_values('distance')\n",
    "\n",
    "        # Return self\n",
    "        return temp\n",
    "\n",
    "    def region(\n",
    "        self,\n",
    "        country: str,\n",
    "        state: str = None\n",
    "    ) -> 'Stations':\n",
    "        \"\"\"\n",
    "        Filter weather stations by country/region code\n",
    "        \"\"\"\n",
    "\n",
    "        # Create temporal instance\n",
    "        temp = copy(self)\n",
    "\n",
    "        # Country code\n",
    "        temp.stations = temp.stations[temp.stations['country'] == country]\n",
    "\n",
    "        # State code\n",
    "        if state is not None:\n",
    "            temp.stations = temp.stations[temp.stations['region'] == state]\n",
    "\n",
    "        # Return self\n",
    "        return temp\n",
    "\n",
    "    def bounds(\n",
    "        self,\n",
    "        top_left: tuple,\n",
    "        bottom_right: tuple\n",
    "    ) -> 'Stations':\n",
    "        \"\"\"\n",
    "        Filter weather stations by geographical bounds\n",
    "        \"\"\"\n",
    "\n",
    "        # Create temporal instance\n",
    "        temp = copy(self)\n",
    "\n",
    "        # Return stations in boundaries\n",
    "        temp.stations = temp.stations[\n",
    "            (temp.stations['latitude'] <= top_left[0]) &\n",
    "            (temp.stations['latitude'] >= bottom_right[0]) &\n",
    "            (temp.stations['longitude'] <= bottom_right[1]) &\n",
    "            (temp.stations['longitude'] >= top_left[1])\n",
    "        ]\n",
    "\n",
    "        # Return self\n",
    "        return temp\n",
    "\n",
    "    def inventory(\n",
    "        self,\n",
    "        granularity: str,\n",
    "        required: Union[bool, datetime, tuple]\n",
    "    ) -> 'Stations':\n",
    "        \"\"\"\n",
    "        Filter weather stations by inventory data\n",
    "        \"\"\"\n",
    "\n",
    "        # Create temporal instance\n",
    "        temp = copy(self)\n",
    "\n",
    "        if required is True:\n",
    "            # Make sure data exists at all\n",
    "            temp.stations = temp.stations[\n",
    "                (pd.isna(temp.stations[granularity + '_start']) == False)\n",
    "            ]\n",
    "        elif isinstance(required, tuple):\n",
    "            # Make sure data exists across period\n",
    "            temp.stations = temp.stations[\n",
    "                (pd.isna(temp.stations[granularity + '_start']) == False) &\n",
    "                (temp.stations[granularity + '_start'] <= required[0]) &\n",
    "                (\n",
    "                    temp.stations[granularity + '_end'] +\n",
    "                    timedelta(seconds=temp.max_age)\n",
    "                    >= required[1]\n",
    "                )\n",
    "            ]\n",
    "        else:\n",
    "            # Make sure data exists on a certain day\n",
    "            temp.stations = temp.stations[\n",
    "                (pd.isna(temp.stations[granularity + '_start']) == False) &\n",
    "                (temp.stations[granularity + '_start'] <= required) &\n",
    "                (\n",
    "                    temp.stations[granularity + '_end'] +\n",
    "                    timedelta(seconds=temp.max_age)\n",
    "                    >= required\n",
    "                )\n",
    "            ]\n",
    "\n",
    "        return temp\n",
    "\n",
    "    def convert(\n",
    "        self,\n",
    "        units: dict\n",
    "    ) -> 'Stations':\n",
    "        \"\"\"\n",
    "        Convert columns to a different unit\n",
    "        \"\"\"\n",
    "\n",
    "        # Create temporal instance\n",
    "        temp = copy(self)\n",
    "\n",
    "        # Change data units\n",
    "        for parameter, unit in units.items():\n",
    "            if parameter in temp.stations.columns.values:\n",
    "                temp.stations[parameter] = temp.stations[parameter].apply(\n",
    "                    unit)\n",
    "\n",
    "        # Return class instance\n",
    "        return temp\n",
    "\n",
    "    def count(self) -> int:\n",
    "        \"\"\"\n",
    "        Return number of weather stations in current selection\n",
    "        \"\"\"\n",
    "\n",
    "        return len(self.stations.index)\n",
    "\n",
    "    def fetch(\n",
    "        self,\n",
    "        limit: int = None,\n",
    "        sample: bool = False\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Fetch all weather stations or a (sampled) subset\n",
    "        \"\"\"\n",
    "\n",
    "        # Copy DataFrame\n",
    "        temp = copy(self.stations)\n",
    "\n",
    "        # Return limited number of sampled entries\n",
    "        if sample and limit:\n",
    "            return temp.sample(limit)\n",
    "\n",
    "        # Return limited number of entries\n",
    "        if limit:\n",
    "            return temp.head(limit)\n",
    "\n",
    "        # Return all entries\n",
    "        return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72d1077e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from meteostat import Stations\n",
    "\n",
    "\n",
    "class Point:\n",
    "\n",
    "    \"\"\"\n",
    "    Automatically select weather stations by geographic location\n",
    "    \"\"\"\n",
    "\n",
    "    # The interpolation method (weighted or nearest)\n",
    "    method: str = 'weighted'\n",
    "\n",
    "    # Maximum radius for nearby stations\n",
    "    radius: int = 35000\n",
    "\n",
    "    # Maximum difference in altitude\n",
    "    alt_range: int = 350\n",
    "\n",
    "    # Maximum number of stations\n",
    "    max_count: int = 4\n",
    "\n",
    "    # Adapt temperature data based on altitude\n",
    "    adapt_temp: bool = True\n",
    "\n",
    "    # Distance Weight\n",
    "    weight_dist: float = 0.6\n",
    "\n",
    "    # Altitude Weight\n",
    "    weight_alt: float = 0.4\n",
    "\n",
    "    # The latitude\n",
    "    lat: float = None\n",
    "\n",
    "    # The longitude\n",
    "    lon: float = None\n",
    "\n",
    "    # The altitude\n",
    "    alt: int = None\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        lat: float,\n",
    "        lon: float,\n",
    "        alt: int = None\n",
    "    ) -> None:\n",
    "\n",
    "        self.lat = lat\n",
    "        self.lon = lon\n",
    "        self.alt = alt\n",
    "\n",
    "        if alt is None:\n",
    "            self.adapt_temp = False\n",
    "\n",
    "    def get_stations(self, granularity: str, start: datetime, end: datetime):\n",
    "        \"\"\"\n",
    "        Get list of nearby weather stations\n",
    "        \"\"\"\n",
    "\n",
    "        # Get nearby weather stations\n",
    "        stations = Stations()\n",
    "        stations = stations.nearby(self.lat, self.lon, self.radius)\n",
    "\n",
    "        # Guess altitude if not set\n",
    "        if self.alt is None:\n",
    "            self.alt = stations.fetch().head(self.max_count)[\n",
    "                'elevation'].mean()\n",
    "\n",
    "        # Apply inventory filter\n",
    "        stations = stations.inventory(granularity, (start, end))\n",
    "\n",
    "        # Apply altitude filter\n",
    "        stations = stations.fetch()\n",
    "        stations = stations[abs(self.alt -\n",
    "                                stations['elevation']) <= self.alt_range]\n",
    "\n",
    "        # Calculate score values\n",
    "        stations['score'] = ((1 - (stations['distance'] / self.radius)) * self.weight_dist) + (\n",
    "            (1 - (abs(self.alt - stations['elevation']) / self.alt_range)) * self.weight_alt)\n",
    "\n",
    "        # Sort by score (descending)\n",
    "        stations = stations.sort_values('score', ascending=False)\n",
    "\n",
    "        return stations.head(self.max_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7afbb504",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ufunc 'deg2rad' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m lat\u001b[38;5;241m=\u001b[39mrow[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      8\u001b[0m lon\u001b[38;5;241m=\u001b[39mrow[\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m----> 9\u001b[0m stations\u001b[38;5;241m=\u001b[39m\u001b[43mstations\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnearby\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlat\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m station\u001b[38;5;241m=\u001b[39mstations\u001b[38;5;241m.\u001b[39mfetch(\u001b[38;5;241m6\u001b[39m)\n\u001b[1;32m     11\u001b[0m start\u001b[38;5;241m=\u001b[39mdatetime(\u001b[38;5;241m2000\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/MDA/lib/python3.9/site-packages/meteostat/interface/stations.py:118\u001b[0m, in \u001b[0;36mStations.nearby\u001b[0;34m(self, lat, lon, radius)\u001b[0m\n\u001b[1;32m    115\u001b[0m temp \u001b[38;5;241m=\u001b[39m copy(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# Get distance for each station\u001b[39;00m\n\u001b[0;32m--> 118\u001b[0m temp\u001b[38;5;241m.\u001b[39m_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistance\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mget_distance\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlatitude\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlongitude\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;66;03m# Filter by radius\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m radius:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/MDA/lib/python3.9/site-packages/meteostat/utilities/helpers.py:22\u001b[0m, in \u001b[0;36mget_distance\u001b[0;34m(lat1, lon1, lat2, lon2)\u001b[0m\n\u001b[1;32m     19\u001b[0m radius \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m6371000\u001b[39m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Degress to radian\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m lat1, lon1, lat2, lon2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(np\u001b[38;5;241m.\u001b[39mdeg2rad, [lat1, lon1, lat2, lon2])\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Deltas\u001b[39;00m\n\u001b[1;32m     25\u001b[0m dlat \u001b[38;5;241m=\u001b[39m lat2 \u001b[38;5;241m-\u001b[39m lat1\n",
      "\u001b[0;31mTypeError\u001b[0m: ufunc 'deg2rad' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
     ]
    }
   ],
   "source": [
    "urlemdat = 'https://github.com/Themaoyc/MDA/blob/main/Data/emdat%20heatwave.csv?raw=true'\n",
    "df = pd.read_csv(urlemdat)\n",
    "df\n",
    "all=pd.DataFrame()\n",
    "for row in df:\n",
    "    stations=Stations()\n",
    "    lat=row[1]\n",
    "    lon=row[2]\n",
    "    stations=stations.nearby(lat,lon)\n",
    "    station=stations.fetch(6)\n",
    "    start=datetime(2000,1,1)\n",
    "    end=datetime(2020,12,31)\n",
    "    data = Daily(station, start, end)\n",
    "    data = data.aggregate('M')\n",
    "    data=data.fetch()\n",
    "    data['datetime'] = data.index.get_level_values('time')\n",
    "    data=data.reset_index(drop=True,inplace=False)\n",
    "    a=data.groupby('datetime', as_index=False)['tavg'].mean()\n",
    "    b=data.groupby('datetime', as_index=False)['tmin'].min()\n",
    "    c=data.groupby('datetime', as_index=False)['tmax'].max()\n",
    "    d=data.groupby('datetime', as_index=False)['prcp'].mean()\n",
    "    e=data.groupby('datetime', as_index=False)['wspd'].mean()\n",
    "    final=pd.merge(a,b)\n",
    "    final=pd.merge(final,c)\n",
    "    final=pd.merge(final,d)\n",
    "    final=pd.merge(final,e)\n",
    "    country=row[0]\n",
    "    final.insert(0,'country',country)   \n",
    "    year=row[3]\n",
    "    month=row[4]\n",
    "    heatwave=[]\n",
    "    finallist=final.values.tolist()\n",
    "    heatwave=[]\n",
    "    for j in finallist:\n",
    "        if j[1].year ==  year and j[1].month == month:\n",
    "            heatwave.append('1')\n",
    "        else:\n",
    "            heatwave.append('0')\n",
    "    heatwave=pd.DataFrame(heatwave)\n",
    "    final=pd.concat([final, heatwave], axis=1)\n",
    "    all=all.append(final)\n",
    "all.to_csv('newfinalweather.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3805e210",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
